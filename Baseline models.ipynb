{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for SwDS dissertation 2\n",
    "#### This file contains code for the baseline models (Section 2)\n",
    "\n",
    "#### Yilun Dong (s1994256), August/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import scipy\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data frames from the csv file\n",
    "train_original = pd.read_csv('quora_train.csv')\n",
    "test_original = pd.read_csv('quora_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the training data is 323478\n",
      "The length of the test data is 80870\n"
     ]
    }
   ],
   "source": [
    "# drop nan rows\n",
    "train = train_original.drop([train_original.index[182601] , train_original.index[219751]])\n",
    "test = test_original.drop([test_original.index[1495]])\n",
    "\n",
    "print('The length of the training data is', len(train))\n",
    "print('The length of the test data is', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop question ID and pairing ID\n",
    "train = train.drop(train_original.columns[[0,1,2,3]], axis=1)\n",
    "test = test.drop(test_original.columns[[0,1,2,3]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define punctuation, stemmer and stop words\n",
    "punctuation = string.punctuation\n",
    "stemmer_sb = nltk.stem.SnowballStemmer('english')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def replaceNumbers(text):\n",
    "    '''\n",
    "    This function replaces numbers with words with space. For example, `100` would be replaced by `one zero zero`.\n",
    "    '''\n",
    "    scheme = {\n",
    "        '0': 'zero',\n",
    "        '1': 'one',\n",
    "        '2': 'two',\n",
    "        '3': 'three',\n",
    "        '4': 'four',\n",
    "        '5': 'five',\n",
    "        '6': 'six',\n",
    "        '7': 'seven',\n",
    "        '8': 'eight',\n",
    "        '9': 'nine'\n",
    "    }\n",
    "    for character, replacement in scheme.items():\n",
    "        text = text.replace(character, ' ' + replacement + ' ')\n",
    "    return text\n",
    "\n",
    "def textCleaner(text):\n",
    "    '''\n",
    "    This function:\n",
    "    1. substitutes punctuation defined above with blank space;\n",
    "    2. strips the text and convert the letters to lower case;\n",
    "    3. extracts the stems of the words in the text using stemmer defined above if `stemming = True`;\n",
    "    4. removes the stop words defined above.\n",
    "    '''\n",
    "    text = re.sub(r'[{}]+'.format(punctuation), ' ' , text)\n",
    "    text = text.strip().lower()\n",
    "    text = replaceNumbers(text)\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    word_list = list(map(stemmer_sb.stem, word_list))\n",
    "    word_list = [word for word in word_list if not word in stop_words]\n",
    "    new_text = ' '.join(word_list)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doe ban five zero zero one zero zero zero rupe...</td>\n",
       "      <td>ban five zero zero one zero zero zero rupe not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hardest thing rais children georgia</td>\n",
       "      <td>hardest thing rais children mexico</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>utopia top competitor</td>\n",
       "      <td>axi four one top competitor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want improv read skill read english news everi...</td>\n",
       "      <td>read newspap help improv english</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gain weight natur way</td>\n",
       "      <td>gain weight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323475</th>\n",
       "      <td>win trump clinton</td>\n",
       "      <td>indict first trump clinton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323476</th>\n",
       "      <td>best earphon one zero zero zero rs</td>\n",
       "      <td>best earphon one zero zero zero rs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323477</th>\n",
       "      <td>song make cri whi</td>\n",
       "      <td>song make cri ever</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323478</th>\n",
       "      <td>tast sperm</td>\n",
       "      <td>tast sperm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323479</th>\n",
       "      <td>becom mental strong</td>\n",
       "      <td>one becom emot mental strong life</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323478 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "0       doe ban five zero zero one zero zero zero rupe...   \n",
       "1                     hardest thing rais children georgia   \n",
       "2                                   utopia top competitor   \n",
       "3       want improv read skill read english news everi...   \n",
       "4                                   gain weight natur way   \n",
       "...                                                   ...   \n",
       "323475                                  win trump clinton   \n",
       "323476                 best earphon one zero zero zero rs   \n",
       "323477                                  song make cri whi   \n",
       "323478                                         tast sperm   \n",
       "323479                                becom mental strong   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "0       ban five zero zero one zero zero zero rupe not...             1  \n",
       "1                      hardest thing rais children mexico             0  \n",
       "2                             axi four one top competitor             0  \n",
       "3                        read newspap help improv english             0  \n",
       "4                                             gain weight             1  \n",
       "...                                                   ...           ...  \n",
       "323475                         indict first trump clinton             0  \n",
       "323476                 best earphon one zero zero zero rs             1  \n",
       "323477                                 song make cri ever             1  \n",
       "323478                                         tast sperm             1  \n",
       "323479                  one becom emot mental strong life             1  \n",
       "\n",
       "[323478 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['question1'] = train['question1'].apply(textCleaner)\n",
    "train['question2'] = train['question2'].apply(textCleaner)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pros con legalzoom generat</td>\n",
       "      <td>read review legalzoom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whi doe readi eat poha absorb water instant</td>\n",
       "      <td>ultim teen patti hacker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app like paytm earn profit give mani cash back...</td>\n",
       "      <td>doe paytm earn give extra cash back alreadi di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daili habit great upgrad life</td>\n",
       "      <td>daili habit improv product creativ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video game world would want live</td>\n",
       "      <td>could live ani video game set would live whi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80866</th>\n",
       "      <td>favourit beatl song whi like</td>\n",
       "      <td>favorit beatl song whi like</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80867</th>\n",
       "      <td>legal author rule china claim eight five south...</td>\n",
       "      <td>prove everi bound monoton increas sequenc conv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80868</th>\n",
       "      <td>best simul game android</td>\n",
       "      <td>best simul game android</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80869</th>\n",
       "      <td>peopl still believ world flat</td>\n",
       "      <td>whi peopl current believ earth flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80870</th>\n",
       "      <td>doe one excel math</td>\n",
       "      <td>get better math</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80870 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question1  \\\n",
       "0                             pros con legalzoom generat   \n",
       "1            whi doe readi eat poha absorb water instant   \n",
       "2      app like paytm earn profit give mani cash back...   \n",
       "3                          daili habit great upgrad life   \n",
       "4                       video game world would want live   \n",
       "...                                                  ...   \n",
       "80866                       favourit beatl song whi like   \n",
       "80867  legal author rule china claim eight five south...   \n",
       "80868                            best simul game android   \n",
       "80869                      peopl still believ world flat   \n",
       "80870                                 doe one excel math   \n",
       "\n",
       "                                               question2  is_duplicate  \n",
       "0                                  read review legalzoom             0  \n",
       "1                                ultim teen patti hacker             0  \n",
       "2      doe paytm earn give extra cash back alreadi di...             1  \n",
       "3                     daili habit improv product creativ             1  \n",
       "4           could live ani video game set would live whi             1  \n",
       "...                                                  ...           ...  \n",
       "80866                        favorit beatl song whi like             1  \n",
       "80867  prove everi bound monoton increas sequenc conv...             0  \n",
       "80868                            best simul game android             1  \n",
       "80869                whi peopl current believ earth flat             1  \n",
       "80870                                    get better math             1  \n",
       "\n",
       "[80870 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['question1'] = test['question1'].apply(textCleaner)\n",
    "test['question2'] = test['question2'].apply(textCleaner)\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = np.asarray(train['is_duplicate'].to_list())\n",
    "labels_test = np.asarray(test['is_duplicate'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0     id   qid1   qid2  \\\n",
      "100       16973  16973  33875  33876   \n",
      "\n",
      "                                        question1  \\\n",
      "100  How many submarines should Indian Navy have?   \n",
      "\n",
      "                                             question2  is_duplicate  \n",
      "100  What should i join? Indian Navy or Merchant Navy?             0  \n",
      "                     question1                       question2  is_duplicate\n",
      "100  mani submarin indian navi  join indian navi merchant navi             0\n"
     ]
    }
   ],
   "source": [
    "# sample of the comparison between processed and original questions\n",
    "print(train_original.loc[[100]])\n",
    "print(train.loc[[100]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Fitting the model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84     51191\n",
      "           1       0.82      0.53      0.64     29679\n",
      "\n",
      "    accuracy                           0.78     80870\n",
      "   macro avg       0.80      0.73      0.74     80870\n",
      "weighted avg       0.79      0.78      0.77     80870\n",
      "\n",
      "[[47705  3486]\n",
      " [14021 15658]]\n"
     ]
    }
   ],
   "source": [
    "print('Preparing data...')\n",
    "\n",
    "bow = CountVectorizer(analyzer = 'word', token_pattern = r'\\w{1,}')\n",
    "bow.fit(train['question1'].append(train['question2']))\n",
    "\n",
    "x1_train_bow = bow.transform(train['question1'].values)\n",
    "x2_train_bow = bow.transform(train['question2'].values)\n",
    "x_train_bow = scipy.sparse.hstack((x1_train_bow, x2_train_bow))\n",
    "y_train_bow = labels_train\n",
    "\n",
    "x1_test_bow = bow.transform(test['question1'].values)\n",
    "x2_test_bow = bow.transform(test['question2'].values)\n",
    "x_test_bow = scipy.sparse.hstack((x1_test_bow, x2_test_bow))\n",
    "y_test_bow = labels_test\n",
    "\n",
    "print('Fitting the model...')\n",
    "\n",
    "np.random.seed(1)\n",
    "model_bow = xgb.XGBClassifier(max_depth = 50, n_estimators = 100, random_state = 1).fit(x_train_bow, y_train_bow) \n",
    "\n",
    "pred_bow = model_bow.predict(x_test_bow)\n",
    "print(classification_report(y_test_bow, pred_bow))\n",
    "print(confusion_matrix(y_test_bow, pred_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF with bag-of-2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Fitting the model...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85     51191\n",
      "           1       0.83      0.53      0.65     29679\n",
      "\n",
      "    accuracy                           0.79     80870\n",
      "   macro avg       0.80      0.73      0.75     80870\n",
      "weighted avg       0.79      0.79      0.77     80870\n",
      "\n",
      "[[47861  3330]\n",
      " [13865 15814]]\n"
     ]
    }
   ],
   "source": [
    "print('Preparing data...')\n",
    "\n",
    "ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,2), max_features = 10000)\n",
    "ngram.fit(train['question1'].append(train['question2']))\n",
    "\n",
    "x1_train_ngram = ngram.transform(train['question1'].values)\n",
    "x2_train_ngram = ngram.transform(train['question2'].values)\n",
    "x_train_ngram = scipy.sparse.hstack((x1_train_ngram, x2_train_ngram))\n",
    "y_train_ngram = labels_train\n",
    "\n",
    "x1_test_ngram = ngram.transform(test['question1'].values)\n",
    "x2_test_ngram = ngram.transform(test['question2'].values)\n",
    "x_test_ngram = scipy.sparse.hstack((x1_test_ngram, x2_test_ngram))\n",
    "y_test_ngram = labels_test\n",
    "   \n",
    "print('Fitting the model...')\n",
    "\n",
    "np.random.seed(1)\n",
    "model_ngram = xgb.XGBClassifier(max_depth=50, n_estimators=100, random_state = 1).fit(x_train_ngram, y_train_ngram) \n",
    "\n",
    "pred_ngram = model_ngram.predict(x_test_ngram)\n",
    "print(classification_report(y_test_ngram, pred_ngram))\n",
    "print(confusion_matrix(y_test_ngram, pred_ngram))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
